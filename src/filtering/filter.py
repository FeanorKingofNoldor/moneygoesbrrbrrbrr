"""
Three-layer filtering system for ODIN
Research-validated thresholds and regime-adaptive scoring
"""

import pandas as pd
import numpy as np
from typing import List, Dict
from datetime import datetime

from config.settings import (
    MIN_DOLLAR_VOLUME,
    MIN_MARKET_CAP,
    MIN_PRICE,
    FILTER_PERCENTILES,
    EXPLORATION_RATIO
)


class OdinFilter:
    """
    Three-layer filter to reduce thousands of stocks to 30 candidates
    """
    
    def __init__(self, database):
        self.db = database
        self.min_dollar_volume = MIN_DOLLAR_VOLUME
        self.min_market_cap = MIN_MARKET_CAP
        self.min_price = MIN_PRICE
        self.exploration_ratio = EXPLORATION_RATIO
    
    def run_full_filter(self, regime: Dict) -> pd.DataFrame:
        """
        Run complete 3-layer filtering process
        """
        print("\nRunning 3-Layer Filter...")
        
        # Get latest stock data from database
        all_stocks = self.db.get_latest_metrics()
        
        if all_stocks.empty:
            print("No stocks in database to filter")
            return pd.DataFrame()
        
        print(f"Starting with {len(all_stocks)} stocks")
        
        # Layer 1: Hard constraints
        layer1 = self.apply_hard_constraints(all_stocks)
        print(f"Layer 1 (Hard constraints): {len(layer1)} stocks remain")
        
        # Layer 2: Regime-based scoring
        layer2 = self.apply_regime_scoring(layer1, regime)
        print(f"Layer 2 (Regime scoring): Scored {len(layer2)} stocks")
        
        # Layer 3: Select final candidates
        final = self.select_candidates(layer2, regime)
        print(f"Layer 3 (Final selection): {len(final)} candidates")
        
        # Save filter results to database
        self.save_filter_results(final, regime)
        
        return final
    
    def apply_hard_constraints(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Layer 1: Remove untradeable stocks
        Research shows this eliminates 80-95% with minimal false negatives
        """
        filtered = df[
            (df['dollar_volume'] > self.min_dollar_volume) &
            (df['price'] > self.min_price)
            # Market cap check disabled since we're estimating it
        ]
        return filtered
    
    def apply_regime_scoring(self, df: pd.DataFrame, regime: Dict) -> pd.DataFrame:
        """
        Layer 2: Score based on current regime
        Weights from research findings
        """
        df = df.copy()
        
        if regime['regime'] in ['extreme_fear', 'fear']:
            # Mean reversion scoring
            df['score'] = (
                0.5 * (30 - df['rsi_2'].clip(0, 30)) / 30 +  # Lower RSI better
                0.3 * df['quality_score'] +                    # Quality matters
                0.2 * df['volume_ratio'].clip(0, 3) / 3       # Volume spike
            )
            
        elif regime['regime'] in ['greed', 'extreme_greed']:
            # Momentum scoring (current regime!)
            df['score'] = (
                0.4 * (df['rsi_2'].clip(50, 100) - 50) / 50 +  # Higher RSI better
                0.3 * df['volume_ratio'].clip(0, 2) / 2 +       # Volume confirmation
                0.3 * df['quality_score']                        # Quality always matters
            )
            
            # Bonus for price above moving average
            if 'sma_20' in df.columns:
                df['above_ma'] = (df['price'] > df['sma_20']).astype(float)
                df['score'] = df['score'] * 0.8 + df['above_ma'] * 0.2
        
        else:  # neutral
            # Balanced scoring
            df['score'] = (
                0.33 * df['quality_score'] +
                0.33 * df['volume_ratio'].clip(0, 2) / 2 +
                0.34 * (50 - abs(df['rsi_2'] - 50)) / 50  # Neutral RSI
            )
        
        return df.sort_values('score', ascending=False)
    
    def select_candidates(self, df: pd.DataFrame, regime: Dict, max_stocks: int = 30) -> pd.DataFrame:
        """
        Layer 3: Select final candidates based on regime percentiles
        Research validated thresholds
        """
        if df.empty:
            return df
        
        # Get percentile threshold for this regime
        percentile = FILTER_PERCENTILES[regime['regime']]
        threshold_score = np.percentile(df['score'], percentile)
        
        # Select stocks above threshold
        candidates = df[df['score'] >= threshold_score]
        
        # Add exploration (15% random from remaining)
        remaining = df[df['score'] < threshold_score]
        if len(remaining) > 0:
            n_explore = min(int(max_stocks * self.exploration_ratio), len(remaining))
            exploration = remaining.sample(n=min(n_explore, len(remaining)))
            candidates = pd.concat([candidates, exploration])
        
        # Limit to max stocks
        final = candidates.nlargest(min(max_stocks, len(candidates)), 'score')
        
        # Add selection metadata
        final['selected'] = True
        final['selection_reason'] = final.apply(
            lambda x: 'top_score' if x['score'] >= threshold_score else 'exploration',
            axis=1
        )
        
        return final
    
    def save_filter_results(self, df: pd.DataFrame, regime: Dict):
        """
        Save filter results for tracking
        """
        if df.empty:
            return
        
        for _, row in df.iterrows():
            self.db.conn.execute("""
            INSERT OR REPLACE INTO filter_results 
            (timestamp, symbol, score, regime, selected)
            VALUES (?, ?, ?, ?, ?)
            """, (
                datetime.now(),
                row['symbol'],
                row['score'],
                regime['regime'],
                True
            ))
        self.db.conn.commit()
    
    def get_filter_stats(self) -> Dict:
        """
        Get statistics about filter performance
        """
        query = """
        SELECT 
            regime,
            COUNT(*) as total_selected,
            AVG(score) as avg_score,
            MAX(score) as max_score
        FROM filter_results
        WHERE selected = 1
        GROUP BY regime
        """
        
        df = pd.read_sql(query, self.db.conn)
        return df.to_dict('records')